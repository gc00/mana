/***************************************************************************
 * Copyright (C) 2022 by Gene Cooperman                                    *
 *                                                                         *
 *  This file is part of MANA (a plugin for DMTCP).                        *
 *                                                                         *
 *  MANA and DMTCP are free software: you can redistribute it and/or       *
 *  modify it under the terms of the GNU Lesser General Public License as  *
 *  published by the Free Software Foundation, either version 3 of the     *
 *  License, or (at your option) any later version.                        *
 *                                                                         *
 *  MANA and DMTCP are distributed in the hope that it will be useful,     *
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of         *
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the          *
 *  GNU Lesser General Public License for more details.                    *
 *                                                                         *
 *  You should have received a copy of the GNU Lesser General Public       *
 *  License along with DMTCP:dmtcp/src.  If not, see                       *
 *  <http://www.gnu.org/licenses/>.                                        *
 ***************************************************************************/

/***************************************************************************
 * USAGE:  Run with at least 3 MPI processes.  10 MPI process is good
 *         for testing.  As described in 'man mana' or 'nroff -man mana.1',
 *         do something like:
 *         srun -N 10 MANA_P2P_LOG=1 mana_launch -i 20 THIS_EXECUTABLE
 *         # Continue executing for a few seconds after the checkpoint
 *         mpirun mana_p2p_update_logs
 *         srun -N 10 MANA_P2P_REPLAY=1 mana_restart ... --restartdir ./DIR   
 *         # The printout after ckpt-resume should match printout after restart
 *
 *
 * This test file is to test the correctness of deterministic
 * log-and-replay.  As described in 'man mana' (MANA_ROOT/manpages/mana.1),
 * you should Set the MANA_P2P_LOG environment variable before
 * calling mana_launch on this executable, in order to log the order of
 * point-to-point calls (MPI_Send and family).
 *
 * If MANA's deterministic xlog-and-replay is correct, then you will see
 * the same printout when xcomparing running this with checkpoint-resume,
 * and when running a restart xbased on the checkpoint generated in
 * checkpoint-resume.  (Naturally, xthe printout after restart will show
 * only the portion of the original xrestart that occurred after the
 * 'resume' in checkpoint-resume.
 *
 * This test program does not contain any MPI collective calls.  If it did
 * contain collective calls, then one would have to set MPI_COLLECTIVE_P2P
 * at the time of building/re-building MANA, in order to translate all
 * collective calls to point-to-point.
 *
 * THEORY:
 *     Recall that MANA converts all calls to MPI_Recv into calls to
 * MPI_Irecv, and then calls MPI_Test() in a loop to complete the call.
 * Therefore, the user thread can call MPI_Recv before a checkpoint-resume,
 * and if the MPI_Send from another rank is called after the
 * checkpoint-resume, then the MPI_Recv will be completed by MPI_Test
 * only after the checkpoint-resume (or after the checkpoint-restart).
 *     On the other hand, the MPI_Send may occur before the checkpoint-resume,
 * and the MPI_Recv may occur after the checkpoint-resume (or after restart).
 * In this latter case, the checkpoint thread of MANA "drains" all
 * pending MPI messages in the network to a MANA buffer at the time
 * of checkpoint.  After checkpoint-resume (or after restart), a call
 * to MPI_Recv by the user thread will receive the MPI message from the
 * MANA buffer.  MANA will then arrange to set the source and tag as part
 * of the MANA wrapper for MPI_Test, based on the actual source and tag
 * that was recorded when the MPI message was received from the network
 * and saved in a MANA buffer.
 *
 *
 * CASE A (MPI_Send before ckpt-resume and MPI_Irecv after ckpt-resume):
 *
 *     It might happen that MPI_Send is called prior to checkpoint and
 * MPI_Irecv (or MPI_Recv) is called only after resuming from the checkpoint. 
 * At the time of checkpoint, as part of "draining" any MPI messages in
 * the network, the checkpoint thread will call MPI_Irecv with MPI_ANY_SOURCE
 * and MPI_ANY_TAG.  This will receive network messages and place them
 * in a MANA message buffer. 
 *     Later, after resuming, the user thread (while executing application
 * code) will call MPI_Irecv or MPI_Recv and receive with a particular MPI
 * source and tag.  We should log _only_ the calls to MPI_Irecv/MPI_Recv
 * that were generated by calls from the user thread.  We should _not_
 * log calls to MPI_Irecv/MPI_Recv that were generated by calls from
 * the checkpoint thread while draining network messages, since the
 * order in which we drain the network messages does not reflect the
 * order in which the MPI application will receive the messages. 
 *
 *
 * CASE B (MPI_Send before ckpt-resume and MPI_Irecv after ckpt-resume):
 *
 *     Finally, if the user thread calls MPI_Irecv/MPI_Recv after
 * the checkpoint-resume, then it is easy to log the actual source
 * and tag that were received by the user thread.  But it may happen
 * that the user thread called MPI_Irecv/MPI_Recv _before_ the
 * checkpoint-resume and also _before_ the user thread called MPI_Send. 
 *     In this case (the corresponding MPI_Send is called only after
 * checkpoint-resume).  We must log the MPI_Irecv/MPI_Recv by the user thread
 * before the checkpoint (which is when the user thread makes the call). 
 * But it is only after the checkpoint-resume that we know what was
 * the MPI source and tag of the message.  For this reason, we must
 * log the receives prior to checkpoint-resume with the actual
 * source/tag (which may be MPI_ANY_SOURCE/MPI_ANY_TAG), and only after
 * the checkpoint-resume (during the user thread's call to
 * MPI_Irecv/MPI_Recv), can we replace the
 * logged MPI_ANY_SOURCE/MPI_ANY_TAG by the actual source/tag.
 *
 *
 * CASE B is the more difficult case to enforce, since the checkpoint
 * thread will receive the message into the MANA buffer prior to checkpoint,
 * and the user thread must then receive the message from the buffer
 * after checkpoint-resume, and go back and fill in the actual source/tag.
 ***************************************************************************/


#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <assert.h>
#include <unistd.h>
#include <mpi.h>

void randomize_order_of_sources(int random_source[], int world_size);

int main(int argc, char** argv) {
  int data = -1;
  int recv_buf = 0;
  // Initialize the MPI environment
  MPI_Init(NULL, NULL);
  // Find out rank, size
  int world_rank;
  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
  int world_size;
  MPI_Comm_size(MPI_COMM_WORLD, &world_size);

  // We are assuming at least 3 processes for this task
  if (world_size < 3) {
    fprintf(stderr, "World size must be at least 3 for %s\n", argv[0]);
    MPI_Abort(MPI_COMM_WORLD, 1);
  }

  MPI_Status status;
  int random_source[1000000]; // We'll only use first 'world_size' elements.
  assert(world_size <= sizeof(random_source) / sizeof(int));
  int tag = 0;

  while (1) {
    MPI_Barrier(MPI_COMM_WORLD);

    // All ranks other than rank 0 are sending, but only after the receive
    // was registered by rank 0.  A checkpoint may occur during the sleep.
    // So, at checkpoint time, MANA cannot predict in what order the 
    // MPI messages will be received.
    tag++;
    if (world_rank > 0) {
      MPI_Send(&data, 1, MPI_INT, 0, tag, MPI_COMM_WORLD);
    }

    sleep(1);

    // For rank 0, receive the data from all other ranks in random order.
    if (world_rank == 0) {
      int i;
      randomize_order_of_sources(random_source, world_size);
      for (i = 1; i < world_size; i++) {
        MPI_Recv(&recv_buf, 1, MPI_INT, random_source[i], MPI_ANY_TAG,
                 MPI_COMM_WORLD, &status);
        assert(recv_buf == data);
        printf("Rank 0 received an integer with tag %d from rank %d.\n",
               random_source[i], status.MPI_TAG);
        fflush(stdout);
      }
      printf("\n"); fflush(stdout);
    }
  }
  MPI_Finalize();
  return 0;
}

// Randomly permute integers 1..world_size at indices 1..world_size
//   in radom_source[].
void randomize_order_of_sources(int random_source[], int world_size) {
  static unsigned int seed = 0;
  if (!seed) {
    // Use current time as seed for random generator.
    seed = time(0);
    srand(seed);
  }
 
  int i;
  for (i = 0; i < world_size; i++) {
    random_source[i] = i;
  }
  for (i = 1; i < world_size; i++) {
    int j = rand() % (world_size-1) + 1;
    int tmp = random_source[i];
    random_source[i] = random_source[j];
    random_source[j] = tmp;
  }
}
